{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tW_hOqEbjKUN"
   },
   "source": [
    "# Lab 6: Word Embeddings and RNNs\n",
    "\n",
    "This lab covers the following topics:\n",
    "- Word encodings and embeddings.\n",
    "- Recurrent neural networks (RNNs).\n",
    "- Long-short term memory (LSTM).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3feBQj-0ol0e"
   },
   "source": [
    "## Exercise 1: Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFgbh2HxboYk"
   },
   "source": [
    "### Exercise 1.1\n",
    "Consider the limited vocabulary list below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtYsABmQi2J4",
    "outputId": "118094e8-2f3c-4d3b-eb87-c5178e642d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "vocab = [\"the\", \"quick\", \"brown\", \"sly\", \"fox\", \"jumped\", \"over\", \"a\", \"lazy\", \"dog\", \"and\",\"found\",\"lion\"]\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zbs1wHxLi5vu"
   },
   "source": [
    "Write a function to create **one hot encodings** of the words. The function maps each word to a vector, where it's location in the vocab list is indicated by 1 and all other entries are zero.\n",
    "\n",
    "For example \"quick\" should map to a torch tensor of dimension 1 with entries [0,1,0....0].\n",
    "\n",
    "Create an extra category for words not in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BrLRb9uki6j8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def one_hot_embedding(token, vocab):\n",
    "  \"\"\"\n",
    "  Token should be a list of words or an indvidual word of length W.\n",
    "  The output shouild be a torch tensor fo size W x (V+1) which gives the one hot encoding for all W tokens\n",
    "  \"\"\"\n",
    "  words = {word: i for i, word in enumerate(vocab)}\n",
    "  vector = torch.zeros(len(token), len(vocab) + 1)\n",
    "\n",
    "  for i, word in enumerate(token):\n",
    "      if word in words:\n",
    "          index = words[word]\n",
    "          vector[i][index] = 1\n",
    "      else:\n",
    "          vector[i][-1] = 1\n",
    "\n",
    "  return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3UfMuPVb_7V"
   },
   "source": [
    "### Exercise 1.2\n",
    "\n",
    "Create a `nn.module` that:\n",
    "\n",
    "1. Takes in a single sentence (a python list).\n",
    "2. Finds the one hot encoding of each word using the function created in exercise 1.1.\n",
    "3. Finds the \"word embedding\" of each word that is $D$-dimensional using the `EmbedddingTable`.\n",
    "4. Returns the average of the word embeddings as a torch vector of size $D$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v__GZavxSD3f"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyWordEmbeddingBag(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(MyWordEmbeddingBag, self).__init__()\n",
    "\n",
    "        self.EmbeddingTable = nn.Parameter(torch.randn(len(vocab)+1,dim))\n",
    "\n",
    "    def forward(self, inputList):\n",
    "        # Your answer here\n",
    "        onehot = one_hot_embedding(inputList, vocab)\n",
    "        emb = torch.matmul(onehot, self.EmbeddingTable)\n",
    "        vector = torch.mean(emb, dim = 0)\n",
    "        return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMRquhRochR6"
   },
   "source": [
    "### Exercise 1.3\n",
    "\n",
    "Instantiate the model with vectors of size $D$= 100 and forward pass the following sentences through your module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Pm5n_BAVcXsm"
   },
   "outputs": [],
   "source": [
    "sent1 = [\"the\", \"quick\", \"brown\"]\n",
    "sent2 = [\"the\", \"sly\", \"fox\", \"jumped\"]\n",
    "sent3 = [\"the\", \"dog\", \"found\",\"a\",\"lion\"]\n",
    "\n",
    "#Instantiate model\n",
    "my_model = MyWordEmbeddingBag(dim = 100)\n",
    "\n",
    "#forward pass sentences\n",
    "assert(len(my_model(sent1))==100)\n",
    "assert(len(my_model(sent2))==100)\n",
    "assert(len(my_model(sent3))==100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q3o3S3BSYrG"
   },
   "source": [
    "### Exercise 1.4\n",
    "\n",
    "Compute the euclidean distance between \"fox\" and \"dog\" using the randomly initialized embedding table in your model above.\n",
    "\n",
    "**Note**: As this is randomly initialized, the distances will also be random in this case. However a trained model using word embeddings will often exhibit closer distances between related words, depending on objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4mVfbx9Qm2-b",
    "outputId": "697ecf71-fb20-43a1-e50c-4737db0c3469"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.8660, grad_fn=<DistBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fox_emb = my_model.EmbeddingTable[vocab.index(\"fox\")]\n",
    "dog_emb = my_model.EmbeddingTable[vocab.index(\"dog\")]\n",
    "\n",
    "torch.dist(fox_emb, dog_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01PBNGFzi-yt"
   },
   "source": [
    "## Exercise 2: Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wR0EGjcKizzi"
   },
   "source": [
    "We will experiment with recurrent networks using the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Axkzlu9BlNVv",
    "outputId": "42899449-cba9-450b-b91f-d7f51fef15a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 60875941.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 5308080.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 20098726.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 308450.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "### Hotfix for very recent MNIST download issue https://github.com/pytorch/vision/issues/1938\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "###\n",
    "\n",
    "dataset = torchvision.datasets.MNIST('./', download=True, transform=transforms.Compose([transforms.ToTensor()]), train=True)\n",
    "train_indices = torch.arange(0, 10000)\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "\n",
    "dataset=torchvision.datasets.MNIST('./', download=True, transform=transforms.Compose([transforms.ToTensor()]), train=False)\n",
    "test_indices = torch.arange(0, 10000)\n",
    "test_dataset = Subset(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MCnDNfcPoIsl"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16,\n",
    "                                          shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7yoR1tI0rUZl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZQ0AVHJlNyM"
   },
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "Consider the following script (modified from https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/02-intermediate/recurrent_neural_network/main.py) which trains an RNN on the MNIST data.\n",
    "\n",
    "Here we can consider each column of the image as an input for each step of the RNN. After 28 steps the model applies a linear layer + cross-entropy loss. We will use this to familiarize ourselves with the nn.RNN module and the nn.LSTM module.\n",
    "\n",
    "First run the cell below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBGhHQv5k6uD",
    "outputId": "173c113c-ec93-4da0-c1e2-dd41584d5d64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm of model.rnn.weight_ih_l0 after the first minibatch: 0.05053286254405975\n",
      "Epoch [1/2], Step [10/157], Loss: 2.5186\n",
      "Epoch [1/2], Step [20/157], Loss: 2.3540\n",
      "Epoch [1/2], Step [30/157], Loss: 2.3452\n",
      "Epoch [1/2], Step [40/157], Loss: 2.3686\n",
      "Epoch [1/2], Step [50/157], Loss: 2.3769\n",
      "Epoch [1/2], Step [60/157], Loss: 2.4580\n",
      "Epoch [1/2], Step [70/157], Loss: 2.3943\n",
      "Epoch [1/2], Step [80/157], Loss: 2.4053\n",
      "Epoch [1/2], Step [90/157], Loss: 2.3125\n",
      "Epoch [1/2], Step [100/157], Loss: 2.3230\n",
      "Epoch [1/2], Step [110/157], Loss: 2.4292\n",
      "Epoch [1/2], Step [120/157], Loss: 2.4536\n",
      "Epoch [1/2], Step [130/157], Loss: 2.2856\n",
      "Epoch [1/2], Step [140/157], Loss: 2.4341\n",
      "Epoch [1/2], Step [150/157], Loss: 2.4378\n",
      "Gradient norm of model.rnn.weight_ih_l0 after the first minibatch: 7.754884791211225e-06\n",
      "Epoch [2/2], Step [10/157], Loss: 2.3199\n",
      "Epoch [2/2], Step [20/157], Loss: 2.3490\n",
      "Epoch [2/2], Step [30/157], Loss: 2.3176\n",
      "Epoch [2/2], Step [40/157], Loss: 2.3935\n",
      "Epoch [2/2], Step [50/157], Loss: 2.4294\n",
      "Epoch [2/2], Step [60/157], Loss: 2.3412\n",
      "Epoch [2/2], Step [70/157], Loss: 2.3068\n",
      "Epoch [2/2], Step [80/157], Loss: 2.3915\n",
      "Epoch [2/2], Step [90/157], Loss: 2.3337\n",
      "Epoch [2/2], Step [100/157], Loss: 2.3534\n",
      "Epoch [2/2], Step [110/157], Loss: 2.3646\n",
      "Epoch [2/2], Step [120/157], Loss: 2.3778\n",
      "Epoch [2/2], Step [130/157], Loss: 2.5044\n",
      "Epoch [2/2], Step [140/157], Loss: 2.4322\n",
      "Epoch [2/2], Step [150/157], Loss: 2.3447\n",
      "Test Accuracy of the model on the 10000 test images: 9.82 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "# Recurrent neural network (many-to-one)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate RNN\n",
    "        out , _ = self.rnn(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #Gradient clipping\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.2)\n",
    "\n",
    "        # Print gradient norm of model.rnn.weight_ih_l0 after the first minibatch\n",
    "        if i == 0:\n",
    "          print(\"Gradient norm of model.rnn.weight_ih_l0 after the first minibatch:\", torch.norm(model.rnn.weight_ih_l0.grad).item())\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kW9D4GAUziV4"
   },
   "source": [
    "### Exercise 2.2\n",
    "\n",
    "Modify the above code (no need to create a new cell) to print the gradient norm of some of the parameters after backward in the the first minibatch.\n",
    "\n",
    "Do this for the following weight parameter: model.rnn.weight_ih_l0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KUsrMOoizsF8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuIgmoPExB5O"
   },
   "source": [
    "### Exercise 2.3\n",
    "\n",
    "Modify the code (in a new cell below) to use LSTM  (and remove the gradient clipping) and rerun the code.\n",
    "\n",
    "**Note**: This is essentially what is done in the original script linked above which you may check for reference or if you get stuck.\n",
    "\n",
    "Run with LSTM and compare the accuracy and the gradient norm for weight_ih_l0 of the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPrhmH231cVe",
    "outputId": "72205e6e-692a-4c20-d339-2d3328a25849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient norm of model.lstm.weight_ih_l0 after backward in minibatch 1: 0.007247603498399258\n",
      "Epoch [1/2], Step [10/157], Loss: 1.9641\n",
      "Epoch [1/2], Step [20/157], Loss: 1.6692\n",
      "Epoch [1/2], Step [30/157], Loss: 1.2135\n",
      "Epoch [1/2], Step [40/157], Loss: 1.0118\n",
      "Epoch [1/2], Step [50/157], Loss: 1.1217\n",
      "Epoch [1/2], Step [60/157], Loss: 0.8427\n",
      "Epoch [1/2], Step [70/157], Loss: 0.6995\n",
      "Epoch [1/2], Step [80/157], Loss: 0.7723\n",
      "Epoch [1/2], Step [90/157], Loss: 0.9962\n",
      "Epoch [1/2], Step [100/157], Loss: 0.4343\n",
      "Epoch [1/2], Step [110/157], Loss: 0.6311\n",
      "Epoch [1/2], Step [120/157], Loss: 0.6711\n",
      "Epoch [1/2], Step [130/157], Loss: 0.3606\n",
      "Epoch [1/2], Step [140/157], Loss: 0.4504\n",
      "Epoch [1/2], Step [150/157], Loss: 0.4286\n",
      "Gradient norm of model.lstm.weight_ih_l0 after backward in minibatch 1: 0.7951779961585999\n",
      "Epoch [2/2], Step [10/157], Loss: 0.6019\n",
      "Epoch [2/2], Step [20/157], Loss: 0.4162\n",
      "Epoch [2/2], Step [30/157], Loss: 0.4365\n",
      "Epoch [2/2], Step [40/157], Loss: 0.4255\n",
      "Epoch [2/2], Step [50/157], Loss: 0.2759\n",
      "Epoch [2/2], Step [60/157], Loss: 0.3637\n",
      "Epoch [2/2], Step [70/157], Loss: 0.3897\n",
      "Epoch [2/2], Step [80/157], Loss: 0.3734\n",
      "Epoch [2/2], Step [90/157], Loss: 0.2643\n",
      "Epoch [2/2], Step [100/157], Loss: 0.3518\n",
      "Epoch [2/2], Step [110/157], Loss: 0.1319\n",
      "Epoch [2/2], Step [120/157], Loss: 0.2784\n",
      "Epoch [2/2], Step [130/157], Loss: 0.2992\n",
      "Epoch [2/2], Step [140/157], Loss: 0.1133\n",
      "Epoch [2/2], Step [150/157], Loss: 0.2715\n",
      "Test Accuracy of the model on the 10000 test images: 91.87 %\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "# Recurrent neural network (many-to-one)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "#         self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #Gradient clipping\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.2)\n",
    "        if i == 0:\n",
    "            grad_norm = torch.norm(model.lstm.weight_ih_l0.grad)\n",
    "            print(f\"Gradient norm of model.lstm.weight_ih_l0 after backward in minibatch {i+1}: {grad_norm}\")\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
